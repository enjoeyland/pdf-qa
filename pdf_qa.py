# query_answer.py

from transformers import AutoTokenizer, AutoModel, AutoModelForVision2Seq, Blip2Processor
import torch
import faiss
import numpy as np

from PIL import Image

from utils import extract_pdf_name, embed_texts


# === í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ ===
TEXT_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
text_tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME, cache_dir="./.cache")
text_model = AutoModel.from_pretrained(TEXT_MODEL_NAME, cache_dir="./.cache")

# === ë©€í‹°ëª¨ë‹¬ QA ëª¨ë¸ (BLIP2) ===
# VISION_MODEL_NAME = "Salesforce/blip2-flan-t5-xl"
# vision_processor = Blip2Processor.from_pretrained(VISION_MODEL_NAME, cache_dir="./.cache")
# vision_model = AutoModelForVision2Seq.from_pretrained(VISION_MODEL_NAME, cache_dir="./.cache")

class QueryAnswerer:
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.VEC_STORE_DIR = f"vector_store/{extract_pdf_name(pdf_path)}"
        self.index = faiss.read_index(f"{self.VEC_STORE_DIR}/index.faiss")
        with open(f"{self.VEC_STORE_DIR}/chunks.npy", "rb") as f:
            self.chunks = np.load(f, allow_pickle=True)
    
    def answer_query(self, query: str, top_k: int = 3) -> str:
        # 1. ì§ˆì˜ ì„ë² ë”©
        query_vec = embed_texts(text_tokenizer, text_model, [query])

        # 2. ìœ ì‚¬ chunk ê²€ìƒ‰
        _, indices = self.index.search(query_vec, top_k)
        selected_chunks = [self.chunks[i] for i in indices[0]]
        print(f"ìœ ì‚¬ chunk ê²€ìƒ‰ ì™„ë£Œ: {selected_chunks}")

        # 3. ì´ë¯¸ì§€ ê¸°ë°˜ ì‘ë‹µ (ìš°ì„ ìˆœìœ„)
        # for chunk in selected_chunks:
        #     if chunk.get("image_path"):
        #         image = Image.open(chunk["image_path"]).convert("RGB")
        #         inputs = vision_processor(images=image, text=query, return_tensors="pt")
        #         with torch.no_grad():
        #             outputs = vision_model.generate(**inputs)
        #         answer = vision_processor.tokenizer.decode(outputs[0], skip_special_tokens=True)
        #         return answer

        # 4. fallback: í…ìŠ¤íŠ¸ chunk ê·¸ëŒ€ë¡œ ë°˜í™˜
        if not selected_chunks:
            return "No relevant information found."
        return selected_chunks[0]["text"]

if __name__ == "__main__":
    PDF_PATH = f"pdf/1.ì œí’ˆì†Œê°œ_ì—ìŠ¤í”¼ë°˜ë„ì²´í†µì‹ .pdf"

    qa = QueryAnswerer(PDF_PATH)
    print("PDF ê¸°ë°˜ QA ì‹œìŠ¤í…œì…ë‹ˆë‹¤.")
    while True:
        query = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (exit ì…ë ¥ ì‹œ ì¢…ë£Œ): ")
        if query.lower() == "exit":
            break
        answer = qa.answer_query(query)
        print(f"\nğŸ§  ë‹µë³€: {answer}")